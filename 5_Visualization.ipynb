{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Visualization\n",
    "\n",
    "Generating plots in \"Neural representations of fear profoundly depend on the situation\"\n",
    "\n",
    "[link to preprint]\n",
    "\n",
    "\n",
    "*Yiyu Wang 2022 Jan*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "# stats\n",
    "from scipy import linalg, ndimage, stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "# nifti handling\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn import decoding\n",
    "from nilearn.masking import apply_mask, intersect_masks\n",
    "from nilearn import image\n",
    "from nilearn.image import new_img_like, load_img, get_data, concat_imgs, mean_img,math_img\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn import surface\n",
    "\n",
    "# nilearn mask:\n",
    "from nilearn.datasets import load_mni152_gm_mask,load_mni152_wm_mask,fetch_surf_fsaverage\n",
    "\n",
    "\n",
    "# plotting modules\n",
    "from nilearn import plotting\n",
    "from nilearn.plotting import plot_stat_map, plot_prob_atlas, plot_img, show\n",
    "from nilearn.image import threshold_img\n",
    "from nilearn.plotting import plot_roi\n",
    "from nilearn import surface\n",
    "fsaverage = fetch_surf_fsaverage()\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_test_res_dir = 'results/permutation_test/'\n",
    "\n",
    "mask_dir = 'masks/'\n",
    "bg_img = mask_dir + 'MNI152_T1_1mm_brain.nii.gz'\n",
    "\n",
    "\n",
    "my_color_three = ['#1f77b4', '#9edae5', '#EF2D2E']\n",
    "color_padding_three =['#1f77b4', '#9edae5','#D3D3D3','#D3D3D3']\n",
    "my_cmap_three = matplotlib.colors.ListedColormap(color_padding_three + my_color_three)\n",
    "\n",
    "\n",
    "my_color_seven = ['#33a02c', '#6a3d9a', '#ff7f00', '#b2df8a', '#FDF85E', '#DA83F8', '#EF2D2E']\n",
    "color_padding = [\"#fd7f6f\", \"#7eb0d5\", \"#ffee65\", \"#b2e061\", \"#bd7ebe\", \"#ffb55a\",\"#8bd3c7\",'#D3D3D3']\n",
    "my_cmap_seven = matplotlib.colors.ListedColormap(color_padding + my_color_seven)\n",
    "\n",
    "vmin = 0.01\n",
    "\n",
    "# surface plot interpolation function:\n",
    "def custom_function(vertices):\n",
    "    return vertices[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether the breakdown map is calculated from the permutation test:\n",
    "calculate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1: Situation Dependent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay by situation-depdent models:\n",
    "\n",
    "\n",
    "if calculate:\n",
    "    # conduction conjunction analysis: calculate overlapping areas between HH, SOSO, SPSP\n",
    "    HH = nib.load(permutation_test_res_dir + f'train_Heights_test_Heights_significant_pearsonr_fwe.nii.gz')\n",
    "    SOSO = nib.load(permutation_test_res_dir + f'train_Social_test_Social_significant_pearsonr_fwe.nii.gz')\n",
    "    SPSP = nib.load(permutation_test_res_dir + f'train_Spiders_test_Spiders_significant_pearsonr_fwe.nii.gz')\n",
    "\n",
    "    HH_mask = math_img('img != 0', img = HH)\n",
    "    SOSO_mask = math_img('img != 0', img = SOSO)\n",
    "    SPSP_mask = math_img('img != 0', img = SPSP)\n",
    "\n",
    "    overlay = math_img('img1 + img2 + img3', img1=HH_mask, img2=SOSO_mask, img3=SPSP_mask)\n",
    "    nib.save(overlay, permutation_test_res_dir + 'SS_overlay.nii.gz')\n",
    "\n",
    "\n",
    "    SO_only =  math_img('img * 2', img = SOSO_mask)\n",
    "    SP_only =  math_img('img * 4', img = SPSP_mask)\n",
    "\n",
    "    overlay_by_sit = math_img('img1 + img2 + img3', img1=HH_mask, img2=SO_only, img3=SP_only)\n",
    "    # swtich value 3 and 4 for better visualization:\n",
    "    overlay_by_sit_data = overlay_by_sit.get_fdata()\n",
    "    three_idx = np.where(overlay_by_sit_data ==3)\n",
    "    four_idx = np.where(overlay_by_sit_data ==4)\n",
    "    overlay_by_sit_data[four_idx] = 3\n",
    "    overlay_by_sit_data[three_idx] = 4\n",
    "    overlay_by_sit = new_img_like(overlay_by_sit, overlay_by_sit_data)\n",
    "    nib.save(overlay_by_sit, permutation_test_res_dir + 'SS_overlay_bySit.nii.gz')\n",
    "    \n",
    "    \n",
    "else:\n",
    "    overlay = nib.load(permutation_test_res_dir + 'SS_overlay.nii.gz')\n",
    "    overlay_by_sit = nib.load(permutation_test_res_dir + 'SS_overlay_bySit.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_data = overlay.get_fdata()\n",
    "\n",
    "one = np.sum(overlay_data==1)\n",
    "two = np.sum(overlay_data==2)\n",
    "three = np.sum(overlay_data==3)\n",
    "\n",
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "# labels = 'Situation dependent', 'Situation dependent:2', 'Situation General'\n",
    "labels = ' ', ' ', ' '\n",
    "sizes = [one, two, three]\n",
    "explode = (0, 0, 0.4)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',textprops={'fontsize': 14},\n",
    "        shadow=False, startangle=90, colors = my_color_three)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1b\n",
    "\n",
    "### Create surface texture for surface plot\n",
    "\n",
    "We will create the overlay by each image because vol_to_surf treats numbers as intensity while the numbers are categories here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "One_only =  math_img('img1 == 1', img1 = overlay)\n",
    "Two_only =  math_img('img1 == 2', img1 = overlay)\n",
    "Three_only =  math_img('img1 == 3', img1 = overlay)\n",
    "\n",
    "\n",
    "texture_threshold = 0.7\n",
    "\n",
    "\n",
    "texture_right1 = surface.vol_to_surf(One_only, fsaverage.pial_right, interpolation='nearest')\n",
    "texture_left1 = surface.vol_to_surf(One_only, fsaverage.pial_left, interpolation='nearest')\n",
    "texture_right1 = np.where(texture_right1>texture_threshold, 1, 0)\n",
    "texture_left1 = np.where(texture_left1>texture_threshold, 1, 0)\n",
    "\n",
    "texture_right2 = surface.vol_to_surf(Two_only, fsaverage.pial_right, interpolation='nearest')\n",
    "texture_left2 = surface.vol_to_surf(Two_only, fsaverage.pial_left, interpolation='nearest')\n",
    "texture_right2 = np.where(texture_right2>texture_threshold, 2, 0)\n",
    "texture_left2 = np.where(texture_left2>texture_threshold, 2, 0)\n",
    "\n",
    "texture_right3 = surface.vol_to_surf(Three_only, fsaverage.pial_right, interpolation='nearest')\n",
    "texture_left3 = surface.vol_to_surf(Three_only, fsaverage.pial_left, interpolation='nearest')\n",
    "texture_right3 = np.where(texture_right3>texture_threshold, 3, 0)\n",
    "texture_left3 = np.where(texture_left3>texture_threshold, 3, 0)\n",
    "\n",
    "\n",
    "\n",
    "sum_texture_right = texture_right3 + texture_right2 + texture_right1\n",
    "sum_texture_left = texture_left3 + texture_left2 + texture_left1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results:\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(14,10), subplot_kw={'projection': '3d'})\n",
    "cbar_ax = fig.add_axes([.91, .3, .03, .4])\n",
    "\n",
    "plotting.plot_surf(fsaverage.infl_left, sum_texture_left,view='lateral', hemi='left',\n",
    "                            colorbar=False, cmap=my_cmap_three, threshold=vmin,vmin=-3, vmax =3,avg_method='median',cbar_vmin=0, cbar_vmax=3,\n",
    "                            bg_map=fsaverage.sulc_left,axes=ax[0,0], darkness = 0.5, inflate=True)\n",
    "\n",
    "\n",
    "plotting.plot_surf(fsaverage.infl_right, sum_texture_right,view='lateral', hemi='right',\n",
    "                            colorbar=False, cmap=my_cmap_three, threshold=vmin,vmin=-3,vmax =3,avg_method='median',cbar_vmin=0, cbar_vmax=3,\n",
    "                            bg_map=fsaverage.sulc_right, axes=ax[0,1], darkness = 0.5, inflate=True)\n",
    "\n",
    "\n",
    "plotting.plot_surf(fsaverage.infl_left, sum_texture_left,view='medial', hemi='left',\n",
    "                            colorbar=False, cmap=my_cmap_three, threshold=vmin,vmin=-3,vmax = 3,avg_method='median',cbar_vmin=0, cbar_vmax=3,\n",
    "                            bg_map=fsaverage.sulc_left,axes=ax[1,0], darkness = 0.5, inflate=True)\n",
    "\n",
    "plotting.plot_surf(fsaverage.infl_right, sum_texture_right,view='medial', hemi='right',\n",
    "                            colorbar=False, cmap=my_cmap_three, threshold=vmin, vmin=-3,vmax =3,cbar_vmin=-3, cbar_vmax=3,\n",
    "                           avg_method='median',\n",
    "                            bg_map=fsaverage.sulc_right,axes=ax[1,1], darkness = 0.5, inflate=True)\n",
    "\n",
    "\n",
    "cmap = matplotlib.colors.ListedColormap(my_color_three)\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=3)\n",
    "cbar = matplotlib.colorbar.ColorbarBase(\n",
    "    cbar_ax,\n",
    "    ticks=[0.5, 1.5, 2.5],\n",
    "    norm=norm,\n",
    "    orientation=\"vertical\",\n",
    "    cmap=cmap,\n",
    "    spacing=\"proportional\",\n",
    ")\n",
    "# cbar_ax.set_yticklabels([\"Situation Dependent\", \"Situation Dependent\", \"Situation General\"])\n",
    "cbar_ax.set_yticklabels([\"Situation Dependent: \\n predicting 1 situation\", \"Situation Dependent: \\n predicting 2 situations\", \"Situation General: \\n predicting all situations\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(overlay_by_sit, cmap=my_cmap_seven, display_mode='x', vmax=7,bg_img=bg_img,black_bg=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2: Situation General Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results\n",
    "permutation_test_res_dir = 'results/permutation_test/'\n",
    "\n",
    "if calculate:\n",
    "    # conjunction analysis: overlap areas between SGSG + SGH, SGSG + SGSO, SGSG + SP:\n",
    "    SG_H = nib.load(permutation_test_res_dir + f'train_Situation_General_test_Heights_significant_pearsonr_fwe.nii.gz')\n",
    "    SG_SO = nib.load(permutation_test_res_dir + f'train_Situation_General_test_Social_significant_pearsonr_fwe.nii.gz')\n",
    "    SG_SP = nib.load(permutation_test_res_dir + f'train_Situation_General_test_Spiders_significant_pearsonr_fwe.nii.gz')\n",
    "    SG_SG = nib.load(permutation_test_res_dir + f'train_Situation_General_test_Situation_General_significant_pearsonr_fwe.nii.gz')\n",
    "\n",
    "\n",
    "    SG_H_mask = math_img('img != 0', img = SG_H)\n",
    "    SG_SO_mask = math_img('img != 0', img = SG_SO)\n",
    "    SG_SP_mask = math_img('img != 0', img = SG_SP)\n",
    "    SG_SG_mask = math_img('img != 0', img = SG_SG)\n",
    "\n",
    "    SGSG_SGH = intersect_masks([SG_H_mask, SG_SG_mask],threshold=1)\n",
    "    SGSG_SGSO = intersect_masks([SG_SO_mask, SG_SG_mask],threshold=1)\n",
    "    SGSG_SGSP = intersect_masks([SG_SP_mask, SG_SG_mask],threshold=1)\n",
    "\n",
    "    overlay = math_img('img1 + img2 + img3', img1=SGSG_SGH, img2=SGSG_SGSO, img3=SGSG_SGSP)\n",
    "    nib.save(overlay, permutation_test_res_dir + 'SGSG_breakdown_overlay.nii.gz')\n",
    "\n",
    "\n",
    "    SGSG_SGH = intersect_masks([SG_H_mask, SG_SG_mask],threshold=1)\n",
    "    SGSG_SGSO = intersect_masks([SG_SO_mask, SG_SG_mask],threshold=1)\n",
    "    SGSG_SGSP = intersect_masks([SG_SP_mask, SG_SG_mask],threshold=1)\n",
    "\n",
    "    SGSO_only =  math_img('img * 2', img = SGSG_SGSO)\n",
    "    SGSP_only =  math_img('img * 4', img = SGSG_SGSP)\n",
    "\n",
    "    overlay_by_sit = math_img('img1 + img2 + img3', img1=SGSG_SGH, img2=SGSO_only, img3=SGSP_only)\n",
    "    # swtich value 3 and 4 for better visualization:\n",
    "    overlay_by_sit_data = overlay_by_sit.get_fdata()\n",
    "    three_idx = np.where(overlay_by_sit_data ==3)\n",
    "    four_idx = np.where(overlay_by_sit_data ==4)\n",
    "    overlay_by_sit_data[four_idx] = 3\n",
    "    overlay_by_sit_data[three_idx] = 4\n",
    "    overlay_by_sit = new_img_like(overlay_by_sit, overlay_by_sit_data)\n",
    "    nib.save(overlay_by_sit, permutation_test_res_dir + 'SGSG_breakdown_overlay_bySit.nii.gz')\n",
    "    \n",
    "else:\n",
    "\n",
    "overlay =nib.load(permutation_test_res_dir + 'SGSG_breakdown_overlay.nii.gz')\n",
    "overlay_by_sit = nib.load(permutation_test_res_dir + 'SGSG_breakdown_overlay_bySit.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_data = overlay.get_fdata()\n",
    "\n",
    "one = np.sum(overlay_data==1)\n",
    "two = np.sum(overlay_data==2)\n",
    "three = np.sum(overlay_data==3)\n",
    "\n",
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "# labels = 'Situation dependent:1', '2.Situation dependent:2', 'Situation General'\n",
    "labels = ' ', ' ', ' '\n",
    "sizes = [one, two, three]\n",
    "explode = (0, 0, 0.4)  # only \"explode\" the 3nd slice - Situation General\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',textprops={'fontsize': 14},\n",
    "        shadow=False, startangle=90, colors = my_color_three)\n",
    "ax1.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Figure 2b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the img\n",
    "One_only =  math_img('img1 == 1', img1 = overlay)\n",
    "Two_only =  math_img('img1 == 2', img1 = overlay)\n",
    "Three_only =  math_img('img1 == 3', img1 = overlay)\n",
    "\n",
    "# since suface rendering is a probablistic interpolation, set a threshold for binarizing:\n",
    "texture_threshold = 0.7\n",
    "\n",
    "texture_right1 = surface.vol_to_surf(One_only, fsaverage.pial_right, interpolation='nearest')\n",
    "texture_left1 = surface.vol_to_surf(One_only, fsaverage.pial_left, interpolation='nearest')\n",
    "texture_right1 = np.where(texture_right1>texture_threshold, 1, 0) \n",
    "texture_left1 = np.where(texture_left1>texture_threshold, 1, 0)\n",
    "\n",
    "texture_right2 = surface.vol_to_surf(Two_only, fsaverage.pial_right, interpolation='nearest')\n",
    "texture_left2 = surface.vol_to_surf(Two_only, fsaverage.pial_left, interpolation='nearest')\n",
    "texture_right2 = np.where(texture_right2>texture_threshold, 2, 0)\n",
    "texture_left2 = np.where(texture_left2>texture_threshold, 2, 0)\n",
    "\n",
    "texture_right3 = surface.vol_to_surf(Three_only, fsaverage.pial_right, interpolation='nearest')\n",
    "texture_left3 = surface.vol_to_surf(Three_only, fsaverage.pial_left, interpolation='nearest')\n",
    "texture_right3 = np.where(texture_right3>texture_threshold, 3, 0)\n",
    "texture_left3 = np.where(texture_left3>texture_threshold, 3, 0)\n",
    "\n",
    "# combine the three \n",
    "sum_texture_right = texture_right3 + texture_right2 + texture_right1\n",
    "sum_texture_left = texture_left3 + texture_left2 + texture_left1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surface plot:\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(14,10), subplot_kw={'projection': '3d'})\n",
    "cbar_ax = fig.add_axes([.91, .3, .03, .4])\n",
    "\n",
    "plotting.plot_surf(fsaverage.infl_left, sum_texture_left,view='lateral', hemi='left',\n",
    "                            colorbar=False, cmap=my_cmap_three, threshold=vmin,vmin=-3, vmax =3,avg_method='median',cbar_vmin=0, cbar_vmax=3,\n",
    "                            bg_map=fsaverage.sulc_left,axes=ax[0,0], darkness = 0.5, inflate=True)\n",
    "\n",
    "\n",
    "plotting.plot_surf(fsaverage.infl_right, sum_texture_right,view='lateral', hemi='right',\n",
    "                            colorbar=False, cmap=my_cmap_three, threshold=vmin,vmin=-3,vmax =3,avg_method='median',cbar_vmin=0, cbar_vmax=3,\n",
    "                            bg_map=fsaverage.sulc_right, axes=ax[0,1], darkness = 0.5, inflate=True)\n",
    "\n",
    "\n",
    "plotting.plot_surf(fsaverage.infl_left, sum_texture_left,view='medial', hemi='left',\n",
    "                            colorbar=False, cmap=my_cmap_three, threshold=vmin,vmin=-3,vmax = 3,avg_method='median',cbar_vmin=0, cbar_vmax=3,\n",
    "                            bg_map=fsaverage.sulc_left,axes=ax[1,0], darkness = 0.5, inflate=True)\n",
    "\n",
    "plotting.plot_surf(fsaverage.infl_right, sum_texture_right,view='medial', hemi='right',\n",
    "                            colorbar=False, cmap=my_cmap_three, threshold=vmin, vmin=-3,vmax =3,cbar_vmin=-3, cbar_vmax=3,\n",
    "                           avg_method='median',\n",
    "                            bg_map=fsaverage.sulc_right,axes=ax[1,1], darkness = 0.5, inflate=True)\n",
    "\n",
    "\n",
    "cmap = matplotlib.colors.ListedColormap(my_color_three)\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=3)\n",
    "cbar = matplotlib.colorbar.ColorbarBase(\n",
    "    cbar_ax,\n",
    "    ticks=[0.5, 1.5, 2.5],\n",
    "    norm=norm,\n",
    "    orientation=\"vertical\",\n",
    "    cmap=cmap,\n",
    "    spacing=\"proportional\",\n",
    ")\n",
    "# cbar_ax.set_yticklabels([\"Situation Dependent\", \"Situation Dependent\", \"Situation General\"])\n",
    "cbar_ax.set_yticklabels([\"Situation Dependent: \\n predicting 1 situation\", \"Situation Dependent: \\n predicting 2 situations\", \"Situation General: \\n predicting all situations\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2c\n",
    "\n",
    "### plot brain slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(overlay_by_sit, cmap=my_cmap_seven, display_mode='x', vmax=7,bg_img=bg_img,black_bg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
